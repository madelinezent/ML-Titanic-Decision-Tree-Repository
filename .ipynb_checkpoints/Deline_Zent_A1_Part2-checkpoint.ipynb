{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Implementing a Decision Tree\n",
    "# Deline Zent - 10/18/20\n",
    "# Import standard libraries and libraries included in assignment description\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib as mp\n",
    "import seaborn as sb\n",
    "import statistics\n",
    "import pickle\n",
    "from scipy.stats import entropy\n",
    "from statistics import mode, StatisticsError\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from graphviz import Digraph\n",
    "from sklearn import tree as sk_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look at unique and null values to fill and change the data.\n",
      "Unique values for Survived: 2\n",
      "Null values for Survived: 0\n",
      "Unique values for Pclass: 3\n",
      "Null values for Pclass: 0\n",
      "Unique values for Name: 891\n",
      "Null values for Name: 0\n",
      "Unique values for Sex: 2\n",
      "Null values for Sex: 0\n",
      "Unique values for Age: 89\n",
      "Null values for Age: 177\n",
      "Unique values for SibSp: 7\n",
      "Null values for SibSp: 0\n",
      "Unique values for Parch: 7\n",
      "Null values for Parch: 0\n",
      "Unique values for Ticket: 681\n",
      "Null values for Ticket: 0\n",
      "Unique values for Fare: 248\n",
      "Null values for Fare: 0\n",
      "Unique values for Cabin: 148\n",
      "Null values for Cabin: 687\n",
      "Unique values for Embarked: 4\n",
      "Null values for Embarked: 2\n"
     ]
    }
   ],
   "source": [
    "# Read in .csv file\n",
    "titanic = pd.read_csv(\"./titanic.csv\", index_col=\"PassengerId\")\n",
    "\n",
    "# Part 2b: Convert any continuous features into binary features or categorical features by thresholding. \n",
    "\n",
    "# View unique and null values for each attribute\n",
    "print(\"Look at unique and null values to fill and change the data.\")\n",
    "for attribute in titanic.columns.values:\n",
    "    print(f'Unique values for {attribute}: {len(titanic[attribute].unique())}')\n",
    "    print(f'Null values for {attribute}: {titanic[attribute].isnull().sum()}')\n",
    " \n",
    " # Since every name is unique, ticket numbers are only 24% unique, and cabin is only 76% null, \n",
    "# we can get rid of these attributes. Additionally, since cabin and tickets are objects they\n",
    "# cannot be easily made discrete. \n",
    "titanic = titanic.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "\n",
    "# Find the median or mode of each attribute.\n",
    "tit_pclass_median = titanic['Pclass'].median()\n",
    "tit_age_median = titanic['Age'].median() \n",
    "tit_sibsp_median = titanic['SibSp'].median()\n",
    "tit_parch_median = titanic['Parch'].median()\n",
    "tit_fare_median = titanic['Fare'].median()\n",
    "tit_embarked_mode = titanic['Embarked'].mode()[0]\n",
    "\n",
    "# Fill null values within each attribute.\n",
    "titanic['Pclass'].fillna(tit_pclass_median, inplace=True)\n",
    "titanic['Age'].fillna(tit_age_median, inplace=True)\n",
    "titanic['SibSp'].fillna(tit_sibsp_median, inplace=True)\n",
    "titanic['Parch'].fillna(tit_parch_median, inplace=True)\n",
    "titanic['Fare'].fillna(tit_fare_median, inplace=True)\n",
    "titanic['Embarked'].fillna(tit_embarked_mode, inplace=True)\n",
    "\n",
    "# Discretize age and fare.\n",
    "titanic['Age'] = pd.cut(titanic['Age'], bins=[0.0, 12.0, 18.0, 30.0, 50.0, 65.0, 80.0], labels=[\"child\", \"teen\", \"young adult\", \"middle-aged\", \"old\", \"elderly\"])\n",
    "titanic['Fare'] = pd.cut(titanic['Fare'], bins=[-.5, 8.0, 12.0, 30.0, 80.0, 800.0], labels=[\"poor\", \"lower class\", \"middle class\", \"upper class\", \"rich\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>middle-aged</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>middle class</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>young adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>poor</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>teen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lower class</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>young adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lower class</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>child</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>middle class</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass     Sex          Age  SibSp  Parch          Fare Embarked  \\\n",
       "PassengerId                                                                     \n",
       "863               1  female  middle-aged      0      0  middle class        S   \n",
       "224               3    male  young adult      0      0          poor        S   \n",
       "85                2  female         teen      0      0   lower class        S   \n",
       "681               3  female  young adult      0      0   lower class        Q   \n",
       "536               2  female        child      0      2  middle class        S   \n",
       "\n",
       "             Survived  \n",
       "PassengerId            \n",
       "863                 1  \n",
       "224                 0  \n",
       "85                  1  \n",
       "681                 0  \n",
       "536                 1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2a: Split dataset into training set and test set.\n",
    "\n",
    "features = ['Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n",
    "X = titanic[features]\n",
    "Y = titanic.Survived\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Concatenate train and test set back together\n",
    "train_set = pd.concat([X_train, Y_train], axis=1)\n",
    "test_set = pd.concat([X_test, Y_test], axis=1)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A decision tree node has a feature value and a list of children\n",
    "\n",
    "class DTNode:\n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        self.children = {}\n",
    "    def add_child(self, key, child):\n",
    "        self.children[key] = child\n",
    "    def to_string(self):\n",
    "        child_list = \"\"\n",
    "        for c in self.children:\n",
    "            child_list = child_list[c] + \" \" + child_list[c].feature\n",
    "        print(\"Node Feature: \", self.feature, \"\\n\", \"Child Nodes: \", child_list, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gain of an attribute\n",
    "def gain(data_set, features, target):\n",
    "    \n",
    "    # Calculate the entropy of the data set\n",
    "    negatives = data_set.loc[data_set[target] == 0] \n",
    "    positives = data_set.loc[data_set[target] == 1] \n",
    "    neg_len = len(negatives)\n",
    "    pos_len = len(positives)\n",
    "    tot_len = pos_len + neg_len\n",
    "    my_entropy = entropy([neg_len/tot_len, pos_len/tot_len], base=2)\n",
    "    \n",
    "    # Need to calculate gain by finding positive and negative instances of each \n",
    "    # feature in a label\n",
    "    highest_gain = -0.1\n",
    "    best_classifer = None\n",
    "    for i in features:\n",
    "        unique_vals = data_set[i].unique()\n",
    "        sum = 0\n",
    "        # For every feature sub-type, calculate the instances of + and - values in it\n",
    "        for j in unique_vals:\n",
    "            feat_col = data_set.loc[data_set[i] == j]\n",
    "            feat_neg = len(feat_col.loc[feat_col[target] == 0])\n",
    "            feat_pos = len(feat_col.loc[feat_col[target] == 1])\n",
    "            feat_len = feat_neg + feat_pos\n",
    "            feat_entropy = entropy([feat_pos/feat_len, feat_neg/feat_len], base=2)\n",
    "            feat_entropy = feat_entropy * (feat_len / tot_len)\n",
    "            sum = sum + feat_entropy\n",
    "        feat_gain = my_entropy - sum\n",
    "        # If the gain we calculated for a feature is higher than previous feature's gain\n",
    "        # then this is the best classifying feature\n",
    "        if  feat_gain > highest_gain:\n",
    "            best_classifier = i\n",
    "            highest_gain = feat_gain\n",
    "    return best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2c: Build trees of a depth maximum specified as part of invoking the tree building function. \n",
    "\n",
    "# Create a decision tree class\n",
    "class DT:\n",
    "    def __init__(self, data, max_depth, features, target):\n",
    "        self.data = data\n",
    "        self.max_depth = max_depth\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        print()\n",
    "        if len(data) > 0:\n",
    "            self.root = self.build_tree(self.data, 0, self.features)\n",
    "        else:\n",
    "            self.root = None  \n",
    "        \n",
    "    # We need to build this tree using recursion. \n",
    "    def build_tree(self, data_set, curr_depth, features):\n",
    "        \n",
    "        # If attribute data is empty, return the mode of the original data\n",
    "        if len(features) == 0:\n",
    "            node = DTNode(survived(self.data[self.target].mode()[0]))\n",
    "            return node\n",
    "        \n",
    "        # If all examples are + or -, return a node with their label\n",
    "        if len(data_set[self.target].unique()) < 2:\n",
    "            node = DTNode(survived(list(data_set[self.target])[0]))\n",
    "            return node\n",
    "        \n",
    "        # If we're at the deepest level, return the mode of the target\n",
    "        if curr_depth == self.max_depth:\n",
    "            node = DTNode(survived(data_set[self.target].mode()[0]))\n",
    "            return node\n",
    "        \n",
    "        # Find which of the remaining features has the most gain. \n",
    "        best_classifier = gain(data_set, features, self.target)\n",
    "        node = DTNode(best_classifier)\n",
    "        \n",
    "        # Build the tree\n",
    "        for i in data_set[best_classifier].unique():\n",
    "            \n",
    "            # Make a new copy of the list to pass to each new child\n",
    "            remaining_features = features.copy()\n",
    "            remaining_features.remove(best_classifier)\n",
    "            \n",
    "            # Make a subset of the data_set where the best classifier\n",
    "            # is equal to the unique value i\n",
    "            data_subset = data_set[data_set[best_classifier] == i]\n",
    "            node.add_child(i, self.build_tree(data_subset, curr_depth+1, remaining_features))\n",
    "    \n",
    "        return node\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return string 'dead' or 'alive'\n",
    "def survived(value):\n",
    "    if value == 1:\n",
    "        return 'alive'\n",
    "    return 'dead'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a Decision Tree with the Titanic training set\n",
    "\n",
    "titanic_tree = DT(test_set, 5, features, 'Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./output/tree_viz.sv.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part 2d: Output the learned tree as a visual interpretable model.\n",
    "\n",
    "# If current root doesnt have children\n",
    "def make_visualized_tree(tree, root):\n",
    "    if len(root.children) != 0:\n",
    "        for key in root.children:\n",
    "            tree.node(str(root.children[key]), str(root.children[key].feature))\n",
    "            tree.edge(str(root), str(root.children[key]), label=str(key))\n",
    "            make_visualized_tree(tree, root.children[key])\n",
    "        \n",
    "VT = Digraph(comment='Titanic Tree', format='png')\n",
    "VT.node(str(titanic_tree.root), str(titanic_tree.root.feature))\n",
    "make_visualized_tree(VT, titanic_tree.root)\n",
    "VT.render('./output/tree_viz.sv', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex\n"
     ]
    }
   ],
   "source": [
    "# Part 2d: Output the learned tree as object code.\n",
    "\n",
    "# Make the titanic tree into object code\n",
    "filename = './output/object_code.sav'\n",
    "pickle.dump(titanic_tree, open(filename, 'wb'))\n",
    "\n",
    "# Convert it back\n",
    "tree_object_model = pickle.load(open(filename, 'rb'))\n",
    "# We are able to call correct features from within the tree, for this example, the root \n",
    "# is definitely sex so our dump and load worked!\n",
    "print(tree_object_model.root.feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives:  92\n",
      "False positives:  3\n",
      "True negatives:  150\n",
      "False negatives:  23\n",
      "Accuracy is:  0.9029850746268657\n",
      "Precision is:  0.968421052631579\n",
      "Recall is:  0.8\n",
      "Confusion Matrix:\n",
      " [[150, 3], [23, 92]]\n",
      "Length of test set:  268\n"
     ]
    }
   ],
   "source": [
    "# Part 2e: Output a confusion matrix from the constructed tree on the test set. \n",
    "\n",
    "def calc_stats(X, target_attribute=\"Survived\"):\n",
    "    \n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    true_negatives = 0\n",
    "\n",
    "    #For every value in the test, identify it\n",
    "    for i in range(len(X)):\n",
    "        instance = X.iloc[i]\n",
    "        instance_label = instance[target_attribute]\n",
    "        node = titanic_tree.root\n",
    "        # Get instance's value from decision tree's attribute\n",
    "        node_feature = node.feature\n",
    "        while (node.children):\n",
    "            instance_val = instance[node_feature]\n",
    "            if (instance_val in node.children):\n",
    "                node = node.children[instance_val]\n",
    "            else:\n",
    "                false_neg += 1\n",
    "                break\n",
    "            node_feature = node.feature\n",
    "        if (node_feature == 'alive' and instance_label == 1):\n",
    "            true_positives += 1\n",
    "        elif (node_feature == 'alive' and instance_label == 0):\n",
    "            false_positives += 1\n",
    "        elif (node_feature == 'dead' and instance_label == 0):\n",
    "            true_negatives += 1\n",
    "        elif (node_feature == 'dead' and instance_label == 1):\n",
    "            false_negatives += 1    \n",
    "    \n",
    "    print(\"True positives: \", true_positives)\n",
    "    print(\"False positives: \",false_positives)\n",
    "    print(\"True negatives: \",true_negatives)\n",
    "    print(\"False negatives: \",false_negatives)\n",
    "    \n",
    "    accuracy = (true_positives + true_negatives) / len(test_set)\n",
    "    print(\"Accuracy is: \", accuracy)\n",
    "    precision = (true_positives) / (true_positives + false_positives)\n",
    "    print(\"Precision is: \", precision)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    print(\"Recall is: \", recall)\n",
    "    confusion_matrix = [[true_negatives, false_positives], [false_negatives, true_positives]]\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix)\n",
    "    print(\"Length of test set: \", len(test_set))\n",
    "\n",
    "calc_stats(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sci-Kit Confusion Matrix:\n",
      " [[129  24]\n",
      " [ 42  73]]\n",
      "Scikit Accuracy:  0.753731343283582\n",
      "Sci_Kit Precision is:  0.7525773195876289\n",
      "Recall is:  0.6347826086956522\n",
      "\n",
      "My tree of depth 5 works better than the sci-kit decision tree.My decision tree has a 90% accuracy, 96% precision, and 80% recallwhile sk has a 75% accuracy, a 75% precision, and 63% recall. I thinkthis is because I took the time to research funds and feature categoriesso I could understand the data better.\n"
     ]
    }
   ],
   "source": [
    "# Part 2g: Compare your coded tree’s metrics with the standard sklearn decision tree implementation.\n",
    "\n",
    "sk_tr = sk_tree.DecisionTreeClassifier()\n",
    "LE = LabelEncoder()\n",
    "train_set['SexCode'] = LE.fit_transform(train_set['Sex'])\n",
    "test_set['SexCode'] = LE.fit_transform(test_set['Sex'])\n",
    "train_set['AgeCode'] = LE.fit_transform(train_set['Age'])\n",
    "test_set['AgeCode'] = LE.fit_transform(test_set['Age'])\n",
    "train_set['FareCode'] = LE.fit_transform(train_set['Fare'])\n",
    "test_set['FareCode'] = LE.fit_transform(test_set['Fare'])\n",
    "train_set['EmbarkedCode'] = LE.fit_transform(train_set['Embarked'])\n",
    "test_set['EmbarkedCode'] = LE.fit_transform(test_set['Embarked'])\n",
    "\n",
    "train_set = train_set.drop(['Sex', 'Fare', 'Age', 'Embarked'], axis=1)\n",
    "test_set = test_set.drop(['Sex', 'Fare', 'Age', 'Embarked'], axis=1)\n",
    "Y_train = train_set.pop('Survived')\n",
    "Y_test = test_set.pop('Survived')\n",
    "\n",
    "# Train and test the sk_tr\n",
    "sk_tr.fit(train_set, Y_train)\n",
    "sk_prediction = sk_tr.predict(test_set)\n",
    "sk_matrix = metrics.confusion_matrix(Y_test, sk_prediction)\n",
    "print(\"Sci-Kit Confusion Matrix:\\n\", sk_matrix)\n",
    "\n",
    "# Get sci-kit measurements\n",
    "sk_true_negatives = sk_matrix[0][0]\n",
    "sk_false_positives = sk_matrix[0][1]\n",
    "sk_false_negatives = sk_matrix[1][0]\n",
    "sk_true_positives = sk_matrix[1][1]\n",
    "\n",
    "sk_accuracy = sk_tr.score(test_set, Y_test)\n",
    "print(\"Scikit Accuracy: \", sk_accuracy)\n",
    "sk_precision = (sk_true_positives) / (sk_true_positives + sk_false_positives)\n",
    "print(\"Sci_Kit Precision is: \", sk_precision)\n",
    "sk_recall = sk_true_positives / (sk_true_positives + sk_false_negatives)\n",
    "print(\"Recall is: \", sk_recall)\n",
    "\n",
    "compare_and_contrast = (\"\\nMy tree of depth 5 works better than the sci-kit decision tree.\"\n",
    "                       \"My decision tree has a 90% accuracy, 96% precision, and 80% recall\"\n",
    "                       \"while sk has a 75% accuracy, a 75% precision, and 63% recall. I think\"\n",
    "                       \"this is because I took the time to research funds and feature categories\"\n",
    "                        \"so I could understand the data better.\")\n",
    "\n",
    "print(compare_and_contrast)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
